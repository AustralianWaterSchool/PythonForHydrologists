{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 1: Data wrangling and multivariate exploratory data analysis\n",
    "\n",
    "This material is prepared for the Australian Water School by Luk Peeters (luk.peeters@csiro.au) and will be presented on June 3rd 2021.\n",
    "\n",
    "The first session of the Python course focusses on data wrangling, importing and exporting various data sets and manipulating data within a Python environment. We'll illustrate this with hydrological time series data and hydrochemistry data sets. The next session will look in greater detail into time series analysis and visualisation. This session will use hydrochemistry data to showcase Python to do multivariate analysis and visualisation.\n",
    "\n",
    "We use Jupyter notebooks in which code can be alternated with text. To have text in a codeblock, mark it as 'Markdown'. A great resource to get you going with writing and formatting text in markdown can be found in the markdown [cheat sheet](https://www.markdownguide.org/cheat-sheet/).\n",
    "\n",
    "## 0. preamble\n",
    "In the great Python slicing tradition, we start counting at 0. Before you can use any of the functionality of a package after you installed it, you need to load it. I prefer to have one code-block at the start of a notebook where I list all the packages I'm going to use. This is not absolutely necessary, but it makes it easier for others when sharing a notebook to quickly see which packages need to be installed.\n",
    "There are two way to load a package:\n",
    "1. import *package* as *short name*\n",
    "2. from *package* import *function*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preamble\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from os import getcwd\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The codeblock above imports 3 packages we'll use a lot: numpy, pandas and matplotlib. To call any function in any of these packages, use the short name followed by a . and the name of the function. With the from *package* import *function* you can import a single function without prefix. The *getcwd* is a function of the os package that gives you the current working directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last line in the preamble ensures that matplotlib figures are displayed interactively in a notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0, 2*np.pi, 25) # create an array with 10 equally spaced points between 0 and 2pi\n",
    "y = np.cos(x) # cosine of x\n",
    "fig, ax = plt.subplots() # create an empty figure\n",
    "ax.plot(x,y,'-ob',label='Data') # plot x vs y, with blue line, with label for the legend\n",
    "ax.set_title('Random numbers') # title for the plot\n",
    "ax.set_xlabel('X-axis') # x-label\n",
    "ax.set_ylabel('Y-axis') # y-label\n",
    "ax.set_xlim(x.min(),x.max()) # set x limits\n",
    "ax.set_ylim(-1.05,1.05) # set y limits\n",
    "ax.grid() # add grid\n",
    "ax.legend() # add legend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot display is interactive, i.e. you can zoom in and out, resize, pan and save the plot. The codeblock shows the basic elements to make a simple plot with matplotlib. A great resource is the [matplotlib cheatsheet](https://github.com/matplotlib/cheatsheets#cheatsheets). I often check the [matplotlib gallery](https://matplotlib.org/stable/gallery/index.html) for inspiration to visualise data. We'll use this basic template throughout the session and tweak it where needed.\n",
    "\n",
    "## 1. Importing and cleaning data - Streamflow time series\n",
    "Most hydrological data is still stored in spreadsheets, either in ASCII-text files, csv-files or excel spreadsheets.\n",
    "We've downloaded a csv file with streamflow discharge from Mt Barker in South Australia from the [Bureau of Meteorology website](http://www.bom.gov.au/waterdata/): **Q_A4260557.csv**. The file has over 40 years of daily data and is too large to open fully in excel.\n",
    "\n",
    "We can open the file with numpy function [numpy.loadtxt](https://numpy.org/doc/stable/reference/generated/numpy.loadtxt.html) and [numpy.genfromtxt](https://numpy.org/doc/stable/reference/generated/numpy.genfromtxt.html#numpy.genfromtxt) to create a numpy array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = np.loadtxt('Q_A4260557.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "well, that didn't work - we need to use some more of the optional arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = np.loadtxt('Q_A4260557.csv',skiprows=11, delimiter=',', usecols = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still no luck. It seems like there is a missing value in the very last row. There are two ways around this; skip the last row or specify how to handle missing values. When you need more control on importing data, it is better to switch to `np.genfromtxt`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = np.genfromtxt('Q_A4260557.csv',\n",
    "                  delimiter=',',\n",
    "                  skip_header=11,\n",
    "                  skip_footer=1,\n",
    "                  usecols = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = np.genfromtxt('Q_A4260557.csv',\n",
    "                  delimiter=',',\n",
    "                  skip_header=11,\n",
    "                  missing_values = '',\n",
    "                  usecols = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check the data we've loaded, we can make a quick plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots() # create an empty figure\n",
    "ax.plot(Q,'-k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is obviously not yet a decent hydrograph. We haven't imported the dates or the additional information on the quality of each data point. It is possible to do this directly in numpy, but it is much easier to do that with pandas [pd.read_csv](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Q = pd.read_csv('Q_A4260557.csv',\n",
    "                header = 8, #which row to use for the headers\n",
    "                index_col = 0, #which row to use as index\n",
    "                parse_dates = True) # index is a data, parse it into a time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q.head() #quick look at dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick and dirty plot\n",
    "plt.figure()\n",
    "Q['Value'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks better, at least this is a hydrograph plot. As you zoom in on the plot, you'll see that the time axis updates as well. From the plot it is clear that there is a gap in the data in 2010, with negative values assigned to it.\n",
    "There might be information in the quality code column. The quality codes are:\n",
    "\n",
    "| Code | Label | Description |\n",
    "|------|-------|:-------------|\n",
    "|10 | quality-A | The record set is the best available given the technologies, techniques and monitoring objectives at the time of classification|\n",
    "|90 | quality-B | The record set is compromised in its ability to truly represent the parameter |\n",
    "|110 | quality-C | The record set is an estimate |\n",
    "|140 | quality-E | The record set's ability to truly represent the monitored parameter is not known |\n",
    "|210 | quality-F | The record set is not of release quality or contains missing data |\n",
    "\n",
    "We can use the [groupby](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.groupby.html) function to quickly cross-tabulate the percentage of data points in each category:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Q.groupby('Quality Code')['Value'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Excercise: the dataset has a column with different codes used for the interpolation of data. Count the number of records for each class**\n",
    "\n",
    "To gain more insight, we can plot the hydrograph, color-coded by its quality label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list the unique quality code values\n",
    "codes = Q['Quality Code'].unique()\n",
    "# create new figure\n",
    "fig,ax = plt.subplots()\n",
    "# for loop, looping through the values in list codes\n",
    "for code in codes:\n",
    "    # find the indices of the records for quality code 'code'\n",
    "    inds = Q['Quality Code']==code \n",
    "    # plot the selected values\n",
    "    ax.plot(Q.index[inds],Q['Value'][inds],'.',label=code) \n",
    "# add legend, outside for loop\n",
    "l = ax.legend()\n",
    "# set title, xlabel and ylabel\n",
    "ax.set_title('Station A4260557')\n",
    "ax.set_xlabel('Time')\n",
    "ax.set_ylabel('Q (m3/s)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a couple of ways that we can clean this dataset:\n",
    "1. Set all values below zero to NaN\n",
    "2. Set all measurements with Quality Code 210 to NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set all values below zero to NaN\n",
    "Q.loc[Q['Value']<0,'Value'] = np.nan\n",
    "# set all values with quality code 210 to NaN\n",
    "Q.loc[Q['Quality Code']==210,'Value'] = np.nan\n",
    "# plot the result\n",
    "fig,ax = plt.subplots()\n",
    "ax.plot(Q.index,Q['Value'],'-k') \n",
    "ax.set_title('Station A4260557')\n",
    "ax.set_xlabel('Time')\n",
    "ax.set_ylabel('Q (m3/s)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've cleaned the data, we can do some analysis, like for instance making a flow duration curve. This code block uses a lot of functions associated with the pandas dataframe: [pd.DataFrame](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an array with values from 0 to 1, in increments of 0.01\n",
    "percs = np.arange(0,1.01,0.01)\n",
    "# calculate percentiles, but remove NaN first\n",
    "discharge = Q['Value'].dropna().quantile(percs)\n",
    "# create a new data frame\n",
    "flowduration = pd.DataFrame(index=percs,columns=['Exceedance Probability','Discharge']) \n",
    "# reverse order of quantiles\n",
    "flowduration['Exceedance Probability'] = 100*(1-percs)\n",
    "flowduration['Discharge'] = discharge[-1::]\n",
    "#plot with log y axis\n",
    "fig,ax = plt.subplots()\n",
    "ax.semilogy(flowduration['Exceedance Probability'],flowduration['Discharge'],'-k')\n",
    "ax.grid()\n",
    "ax.set_xlabel('Exceedance probability')\n",
    "# use Latex formatting\n",
    "ax.set_ylabel(u'Q ($m^3/s$)') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code block above is pretty concise and gives you full control on calculating and plotting the flow duration curve. You might want to repeat this a lot. One way to do this without having to copy the code block over and over again is by creating a function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flowduration(Q):\n",
    "    #create an array with values from 0 to 1, in increments of 0.01\n",
    "    percs = np.arange(0,1.01,0.01)\n",
    "    # calculate percentiles, but remove NaN first\n",
    "    discharge = Q['Value'].dropna().quantile(percs)\n",
    "    # create a new data frame\n",
    "    flowduration = pd.DataFrame(index=percs,columns=['Exceedance Probability','Discharge']) \n",
    "    # reverse order of quantiles\n",
    "    flowduration['Exceedance Probability'] = 100*(1-percs)\n",
    "    flowduration['Discharge'] = discharge[-1::]\n",
    "    #plot with log y axis\n",
    "    fig,ax = plt.subplots()\n",
    "    ax.semilogy(flowduration['Exceedance Probability'],flowduration['Discharge'],'-k')\n",
    "    ax.grid()\n",
    "    ax.set_xlabel('Exceedance probability')\n",
    "    # use Latex formatting\n",
    "    ax.set_ylabel(u'Q ($m^3/s$)') \n",
    "    return(flowduration,fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use this function to illustrate how to save both the figure and the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd,fig = flowduration(Q)\n",
    "# save figure as png\n",
    "fig.savefig('Flowdurationcurve.png')\n",
    "# save figure as csv file - index column by default has no label\n",
    "fd.to_csv('Flowdurationcurve.csv', index_label='Percentile')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Intermezzo: inserting variables in strings\n",
    "A great feature of using scripts is to automate tedious tasks, like loading different files or labeling figures with values from your data-set. Automating such tasks often requires inserting values from variables or arrays into strings. This section gives a quick overview of a couple of different ways to achieve that. A detailed overview can be found on the website [PyFormat](https://pyformat.info/)\n",
    "\n",
    "The 'old' method you'll still often find is based on the '%' operator, while the new method is based on the format function of a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a string with the station name\n",
    "name = 'A4260557'\n",
    "# create a variable with a numeric value\n",
    "Qmax = fd['Discharge'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert the station name in a file name\n",
    "# old\n",
    "filename = 'Flow_duration_%s.csv' % (name)\n",
    "print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new, all version of Python\n",
    "filename = 'Flow_duration_{}.csv'.format(name)\n",
    "print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new, Python >=3.6\n",
    "filename = f'Flow_duration_{name}.csv'\n",
    "print(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you're adding numbers to a string, you can specify the format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# old\n",
    "title = '%s: Qmax = %f m3/s' % (name,Qmax) # no formatting, just float\n",
    "print(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new\n",
    "title = '{}: Qmax = {:4.2f} m3/s'.format(name,Qmax) # 4 characters, 2 decimal places\n",
    "print(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new, Python >=3.6\n",
    "title = f'{name}:\\nQmax = {Qmax:04.0f} m3/s' # 4 characters, 0 decimal places, padding with zeros, \\n for new line\n",
    "print(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Multivariate data: reading from excel\n",
    "Pandas can also read data directly from excel files, using [pd.read_excel](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_excel.html).\n",
    "The dataset we are using is a dataset of groundwater chemistry of South Australia\n",
    "\n",
    "[Gray, David J. and Bardwell, Nicole (2016) Hydrogeochemistry of South Australia: Data Release: Accompanying Notes. CSIRO, Australia. EP156116 34p](https://data.csiro.au/collections/collection/CIcsiro:17862v1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'CSH_SA.xlsx'\n",
    "sheet = 'Data'\n",
    "chem = pd.read_excel(fname,sheet)\n",
    "chem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset has over 30.000 entries and 77 columns. Pandas has recognised the date column and converted these into dates. All the blanks in the dataset are converted to NaN, Not a Number.\n",
    "\n",
    "The function pd.columns prints a list of all the columns in the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chem.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of missing values in this dataframe. The next codeblock summarizes the percentage of records with missing values for each variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of records\n",
    "nsample = len(chem)\n",
    "# number of complete records\n",
    "ncomplete = len(chem.dropna()) # dropna removes any row that contains at least one NaN\n",
    "print('Number of records without missing values = {}'.format(ncomplete))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset has no single record with entries for all variables. The first 7 variables are meta-data. We want to check if there are any records that only have data for the metadata, not for the chemistry. We can use the dropna function again. The next line of code removes any rows that are all NaN for all columns except the first 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chem.dropna(axis=0,how='all',subset=chem.columns[7::],inplace=True)\n",
    "print('Number of records removed = {}'.format(nsample-len(chem)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to cross-tabulate the number of missing values for each variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chem_var_na = chem.isna().sum(axis=0).T\n",
    "chem_var_na"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An easier way to inspect that dataset is to plot it as a bar chart:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "# modify the default figure size\n",
    "fig.set_size_inches(7,10)\n",
    "# create the ticks for a horizontal bar plot\n",
    "ticks = np.arange(len(chem_var_na))\n",
    "# bar plot of percent not NaN\n",
    "ax.barh(ticks,\n",
    "        100-100*(chem_var_na/float(nsample)))\n",
    "# set labels for y-axis\n",
    "ax.set_yticks(ticks)\n",
    "ax.set_yticklabels(chem_var_na.index,fontdict={'fontsize':8})\n",
    "# adjust y-axis limits\n",
    "ax.set_ylim(-1,len(chem.columns))\n",
    "# invert y-axis so meta-data is at the bottom\n",
    "ax.invert_yaxis\n",
    "# change x-axis limits\n",
    "ax.set_xlim(0,100)\n",
    "# set title\n",
    "ax.set_title('GW chemistry SA:\\n{} samples'.format(nsample))\n",
    "# set x axis label\n",
    "ax.set_xlabel('Percent samples with data')\n",
    "# add grid\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also make a plot of how the number of samples with missing values changes through time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same command as before, but now summing per row \n",
    "chem_sample_na = chem.isna().sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "# time series plot, using transparency as many points are overlapping\n",
    "ax.plot(chem['Date'],(len(chem.columns)-chem_sample_na),'.k',alpha=0.02)\n",
    "ax.grid()\n",
    "ax.set_xlabel('Year')\n",
    "ax.set_ylabel('Number of variables measured')\n",
    "ax.set_title('GW chemistry SA')\n",
    "ax.set_ylim(bottom=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Excercise 2: recreate the plot above, but without counting the 7 meta-data variables**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Exploratory Data Analysis\n",
    "Exploratory data analysis is the process of visualising a dataset to formulate hypothesis of the processes that resulted in the data set.\n",
    "Histograms are a standard visualisation to understand the distribution of variables. Python makes it very easy to generate multi-panel figures, so that you can summarise a lot of information in a single composite figure. Below is a code block to make histograms of the major ions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "majorions = ['HCO3_mgL', 'Na_mgL','K_mgL', 'Mg_mgL', 'Ca_mgL', 'Cl_mgL', 'SO4_mgL','NO3N_mgL']\n",
    "plt.figure()\n",
    "for i,ion in enumerate(majorions):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.hist(chem[ion].dropna())\n",
    "    plt.title(ion,fontsize='small')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The histograms show that all data are very skewed. One quick way to deal with left-skewed data is to do a log transform first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "for i,ion in enumerate(majorions):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    # 0 values lead to error in log10\n",
    "    plt.hist(np.log10(chem[ion][chem[ion]>0].dropna()))\n",
    "    plt.title('Log 10 {}'.format(ion),fontsize='small')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A more compact way to show distributions, especially if their scale is similar, is to use violinplots. Below is a violin plot for some of the minor ions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minorions = ['Li_mgL', 'Fe_mgL', 'Mn_mgL', 'Al_mgL', 'Cu_mgL', 'Zn_mgL', 'Pb_mgL', 'As_mgL', 'Cr_mgL','Cd_mgL', 'Ni_mgL']\n",
    "fig,ax = plt.subplots()\n",
    "d = [chem[a].dropna() for a in minorions]\n",
    "ticks = np.arange(0,len(minorions))\n",
    "ax.violinplot(d,positions=ticks,vert=False,showmedians=True)\n",
    "ax.set_yticks(ticks)\n",
    "ax.set_yticklabels(minorions)\n",
    "ax.set_xscale('log')\n",
    "ax.set_title('Minor ions')\n",
    "ax.set_xlabel('Concentration (mg/L)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploratory Data Analysis is also looking for correlations in the dataset. We might look into how some of the variables correlate with pH or TDS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "for i,major in enumerate(majorions):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.loglog(chem['TDSc_mgL'],chem[major],'.k',alpha=0.01)\n",
    "    plt.title(major)\n",
    "    plt.xlabel('TDS (mg/L)')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Excercise: make the same plot, but with pH on the x-axis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A more formal way of exploring correlations is through a correlation matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chemcorr = chem[chem.columns[7::]].corr()\n",
    "chemcorr_sp = chem[chem.columns[7::]].corr('spearman')\n",
    "chemcorr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For large dataset, visualising this as a colored matrix works well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(10,8))\n",
    "q = ax.pcolor(chemcorr_sp,\n",
    "          vmin=-1,vmax=1,\n",
    "          cmap='coolwarm')\n",
    "ax.set_title('Correlation matrix')\n",
    "cbar = plt.colorbar(q,shrink=0.5)\n",
    "a = ax.set_xticks(np.arange(len(chem.columns[7::]))+.5)\n",
    "b = ax.set_xticklabels(chem.columns[7::],rotation=90,fontsize='xx-small')\n",
    "c = ax.set_yticks(np.arange(len(chem.columns[7::]))+.5)\n",
    "d = ax.set_yticklabels(chem.columns[7::],fontsize='xx-small')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Bringing in raster data\n",
    "The package rasterio implements a lot of functionality importing and manipulating raster data. For this session however, we'll stick with numpy and pandas to showcase some general functionality on importing data and interacting with arrays.\n",
    "\n",
    "The raster dataset we're using is a raster with estimated chloride deposition across Australia at a 0.05 degree grid.\n",
    "\n",
    "[Davies, Phil; Crosbie, Russell. Mapping the spatial distribution of chloride deposition across Australia. Journal of Hydrology. 2018; 561:76-88. https://doi.org/10.1016/j.jhydrol.2018.03.051](https://data.csiro.au/collections/collection/CIcsiro:11068v4)\n",
    "\n",
    "The chloride deposition rate in kg/ha/year ($D$) can be used together with the chloride concentration in groundwater ($Cl$) to estimate the recharge to groundwater ($R$) with the following equation:\n",
    "\n",
    "$ R=100\\frac{D}{Cl} $\n",
    "\n",
    "The raster is an ASCII grid file with following structure\n",
    "\n",
    "    ncols         4\n",
    "    nrows         6\n",
    "    xllcorner     0.0\n",
    "    yllcorner     0.0\n",
    "    cellsize      50.0\n",
    "    NODATA_value  -9999\n",
    "    -9999 -9999 5 2\n",
    "    -9999 20 100 36\n",
    "    3 8 35 10\n",
    "    32 42 50 6\n",
    "    88 75 27 9\n",
    "    13 5 1 -9999\n",
    "    \n",
    "We'll read the grid in with `np.loadtxt`. For the metadata (the 1st 6 line), we'll use the more generic `open` command together with `readline`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chloride deposition grid\n",
    "fname = 'cl_deposition_final.txt'\n",
    "# read data in numpy array, skip metadata\n",
    "cl_depo = np.loadtxt(fname,skiprows=6)\n",
    "# create an empty dictionary for the meta-data\n",
    "cl_depo_meta = {}\n",
    "# open the grid file\n",
    "with open(fname) as f:\n",
    "    # while loop, as long as the dict has less than 6 entries\n",
    "    while len(cl_depo_meta)<6:\n",
    "        # readline reads 1 line in the file, the split function splits in a list based on white space\n",
    "        tmp = f.readline().split()\n",
    "        # first item in list is the name for the meta data, second is the value\n",
    "        cl_depo_meta[tmp[0]] = float(tmp[1]) # use float to convert string to float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_depo_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_depo_meta['ncols']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace the NODATA_values with NaN and plot the map with `imshow`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_depo[cl_depo<(cl_depo_meta['NODATA_value']+1)] = np.nan\n",
    "fig,ax = plt.subplots()\n",
    "# modify the default figure size\n",
    "fig.set_size_inches(10,10)\n",
    "p = ax.imshow(cl_depo,\n",
    "          origin = 'upper',\n",
    "          cmap = 'Reds',\n",
    "          extent = (cl_depo_meta['xllcorner'],\n",
    "                   cl_depo_meta['xllcorner']+(cl_depo_meta['ncols']*cl_depo_meta['cellsize']),\n",
    "                   cl_depo_meta['yllcorner'],\n",
    "                   cl_depo_meta['yllcorner']+(cl_depo_meta['nrows']*cl_depo_meta['cellsize'])))\n",
    "cbar = plt.colorbar(p)\n",
    "cbar.set_label('kg/ha/year')\n",
    "ax.set_title('Chloride deposition')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can add the points from the chemistry dataset to the map and zoom in on the chemistry dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zoom in to SA data\n",
    "ax.set_xlim(chem['Long'].min(),chem['Long'].max())\n",
    "ax.set_ylim(chem['Lat'].min(),chem['Lat'].max())\n",
    "# use scatter to plot point with color based on log10 Cl\n",
    "s = ax.scatter(chem['Long'],chem['Lat'],.2,np.log10(chem['Cl_mgL']),cmap='viridis')\n",
    "# add second colorbar\n",
    "cbars = plt.colorbar(s)\n",
    "cbars.set_label('Log10 Cl (mg/L)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate the recharge rate at the sampling locations, we need to extract the values of the chloride deposition from the grid. For this we need to convert the coordinates of the samples into indices of the numpy array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up the coordinates of the grid based on the meta data\n",
    "xmin = cl_depo_meta['xllcorner']\n",
    "xmax = cl_depo_meta['xllcorner']+cl_depo_meta['cellsize']*cl_depo_meta['ncols']\n",
    "ymin = cl_depo_meta['yllcorner']\n",
    "ymax = cl_depo_meta['yllcorner']+cl_depo_meta['cellsize']*cl_depo_meta['nrows']\n",
    "cell = cl_depo_meta['cellsize']\n",
    "# the floor command rounds numbers down to the nearest integer. The astype('int') ensures the result is an integer\n",
    "xind = (np.floor((chem['Long'] - xmin)/cell)).astype('int')\n",
    "# the x-index of 0 is at the top of the grid, so we need to reverse the values\n",
    "yind = (cl_depo_meta['nrows']-np.floor((chem['Lat'] - ymin)/cell)).astype('int')\n",
    "chem['Cl_depo'] = cl_depo[xind,yind]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we know that our code is doing what we expect from it? One simple test is to visualise a copy of the grid and mark all the cells that have samples in, at least according to our calculations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an empty array with same dimensions as cl_depo\n",
    "a = np.zeros_like(cl_depo)*np.nan\n",
    "# give all cells > 0 the value 1\n",
    "a[cl_depo>0] = 1\n",
    "# give all cells with a sample the value 5\n",
    "a[xind,yind] = 5\n",
    "# quick and dirty visualisation\n",
    "plt.figure()\n",
    "# use no interpolation to avoid pixels being affected by neighbours\n",
    "plt.imshow(a,interpolation='none',cmap='Reds')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**excercise: try to figure out what went wrong in selecting grid cells**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have all the information to calculate the recharge rate from the chloride concentration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chem['Recharge'] = 100*(chem['Cl_depo']/chem['Cl_mgL'])\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "# modify the default figure size\n",
    "fig.set_size_inches(10,10)\n",
    "p = ax.imshow(cl_depo,\n",
    "          origin = 'upper',\n",
    "          cmap = 'Reds',\n",
    "          extent = (cl_depo_meta['xllcorner'],\n",
    "                   cl_depo_meta['xllcorner']+(cl_depo_meta['ncols']*cl_depo_meta['cellsize']),\n",
    "                   cl_depo_meta['yllcorner'],\n",
    "                   cl_depo_meta['yllcorner']+(cl_depo_meta['nrows']*cl_depo_meta['cellsize'])))\n",
    "cbar = plt.colorbar(p, shrink=0.5)\n",
    "cbar.set_label('kg/ha/year')\n",
    "ax.set_title('Chloride mass balance')\n",
    "# zoom in to SA data\n",
    "ax.set_xlim(chem['Long'].min(),chem['Long'].max())\n",
    "ax.set_ylim(chem['Lat'].min(),chem['Lat'].max())\n",
    "# use scatter to plot point with color based on recharge\n",
    "s = ax.scatter(chem['Long'],chem['Lat'],.2,chem['Recharge'],cmap='viridis',vmax=250)\n",
    "# add second colorbar\n",
    "cbars = plt.colorbar(s,orientation='horizontal')\n",
    "cbars.set_label('Recharge (mm/yr)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 Intermezzo: Colors\n",
    "Color is crucial in data visualisation, especially when using color to visualize a continuous range of data. Matplotlib has some excellent colormaps that are perceptually uniform and provides a great discussion and comparison of different [colormaps](https://matplotlib.org/stable/tutorials/colors/colormaps.html)\n",
    "\n",
    "Related to choosing colormaps is choosing colors for categorical data or in plotting. [ColorBrewer](https://colorbrewer2.org/#type=sequential&scheme=BuGn&n=3) is a great tool to create color pallettes. Most plotting functions can use RGB or HexRGB values, but there is a range of named colors available. An overview is provided [here](https://matplotlib.org/stable/gallery/color/named_colors.html). The codeblock below is copied from that site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Rectangle\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "\n",
    "def plot_colortable(colors, title, sort_colors=True, emptycols=0):\n",
    "\n",
    "    cell_width = 212\n",
    "    cell_height = 22\n",
    "    swatch_width = 48\n",
    "    margin = 12\n",
    "    topmargin = 40\n",
    "\n",
    "    # Sort colors by hue, saturation, value and name.\n",
    "    if sort_colors is True:\n",
    "        by_hsv = sorted((tuple(mcolors.rgb_to_hsv(mcolors.to_rgb(color))),\n",
    "                         name)\n",
    "                        for name, color in colors.items())\n",
    "        names = [name for hsv, name in by_hsv]\n",
    "    else:\n",
    "        names = list(colors)\n",
    "\n",
    "    n = len(names)\n",
    "    ncols = 4 - emptycols\n",
    "    nrows = n // ncols + int(n % ncols > 0)\n",
    "\n",
    "    width = cell_width * 4 + 2 * margin\n",
    "    height = cell_height * nrows + margin + topmargin\n",
    "    dpi = 72\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(width / dpi, height / dpi), dpi=dpi)\n",
    "    fig.subplots_adjust(margin/width, margin/height,\n",
    "                        (width-margin)/width, (height-topmargin)/height)\n",
    "    ax.set_xlim(0, cell_width * 4)\n",
    "    ax.set_ylim(cell_height * (nrows-0.5), -cell_height/2.)\n",
    "    ax.yaxis.set_visible(False)\n",
    "    ax.xaxis.set_visible(False)\n",
    "    ax.set_axis_off()\n",
    "    ax.set_title(title, fontsize=24, loc=\"left\", pad=10)\n",
    "\n",
    "    for i, name in enumerate(names):\n",
    "        row = i % nrows\n",
    "        col = i // nrows\n",
    "        y = row * cell_height\n",
    "\n",
    "        swatch_start_x = cell_width * col\n",
    "        text_pos_x = cell_width * col + swatch_width + 7\n",
    "\n",
    "        ax.text(text_pos_x, y, name, fontsize=14,\n",
    "                horizontalalignment='left',\n",
    "                verticalalignment='center')\n",
    "\n",
    "        ax.add_patch(\n",
    "            Rectangle(xy=(swatch_start_x, y-9), width=swatch_width,\n",
    "                      height=18, facecolor=colors[name], edgecolor='0.7')\n",
    "        )\n",
    "\n",
    "    return fig\n",
    "\n",
    "plot_colortable(mcolors.BASE_COLORS, \"Base Colors\",\n",
    "                sort_colors=False, emptycols=1)\n",
    "plot_colortable(mcolors.TABLEAU_COLORS, \"Tableau Palette\",\n",
    "                sort_colors=False, emptycols=2)\n",
    "\n",
    "plot_colortable(mcolors.CSS4_COLORS, \"CSS Colors\")\n",
    "\n",
    "# Optionally plot the XKCD colors (Caution: will produce large figure)\n",
    "#xkcd_fig = plot_colortable(mcolors.XKCD_COLORS, \"XKCD Colors\")\n",
    "#xkcd_fig.savefig(\"XKCD_Colors.png\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Excercise: make a plot of TDS vs pH with the datapoints colored 'darkseagreen'**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Multivariate data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Lat','Long','TDSc_mgL', 'pH', 'HCO3_mgL', 'Na_mgL', 'K_mgL', 'Mg_mgL', 'Ca_mgL', 'Cl_mgL', 'SO4_mgL','NO3N_mgL']\n",
    "dat = chem[cols].dropna()\n",
    "dat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we've seen before, the data are very skewed. Before doing any multivariate data analysis it is therefore recommended to normalise data. This is often done by rescaling all variables so their range falls between 0 and 1 or by transforming the variables by subtracting the mean and dividing by the standard deviation. We used log transform earlier for skewed data. This has some drawbacks, especially if there are 0s in the dataset.\n",
    "\n",
    "Another way to normalise data is to calculate the rank, i.e. the position if you were to rank them from smallest to largest. This can be easily done wiith the `rankdata` function from [scipy.stats](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.rankdata.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate rank of data\n",
    "from scipy.stats import rankdata\n",
    "dr = rankdata(np.array(dat[cols[2::]]),axis=0)\n",
    "dr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a wide range of approaches for multivariate data analysis. A great resource is [scikit-learn](https://scikit-learn.org/stable/), which is an easy to use package for machine learning.\n",
    "\n",
    "What we'll look into is dimensionality reduction and manifold learning. The goal is to find a representation of the data in 2D such that samples that are similar are plotted close to each other and samples that are very different are plotted far apart. The [manifold learning page](https://scikit-learn.org/stable/modules/manifold.html#manifold) gives an overview of methods you can use. The method we'll be using is [t-distributed Stochastic Neighbor Embedding](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html#sklearn.manifold.TSNE).\n",
    "\n",
    "We need to import the function from scikit learn, specify the parameters and then train the algorithm with our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "tsne = TSNE(n_components=2, init='pca')\n",
    "X = tsne.fit_transform(dr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is a 2D numpy array with an x and y coordinate for each sample. We can visualise this with `plt.scatter` and color the plot with the rank of each of the variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "for i,col in enumerate(cols[2::]):\n",
    "    ax = plt.subplot(4,3,i+1, aspect=1)\n",
    "    ax.scatter(X[:,0],X[:,1],0.2,dr[:,i],cmap='viridis')\n",
    "    ax.set_title(col)\n",
    "    ax.set_axis_off()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a spatial dataset, so we want to know show this information on a map. I've developed a 2D perceptually colormap that can be used to assign a unique color to each sample, based on the coordinates of the TSNE projection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percuniform_rgb(x,y):\n",
    "    '''\n",
    "    Create RGB values for x,y positions from perceptually uniform colour scheme\n",
    "    IN:\n",
    "        x: [nx1] array of x values\n",
    "        y: [nx1] array of y values\n",
    "    OUT:\n",
    "        rgb: [nx3] array of rgb values\n",
    "    '''\n",
    "    # rescale cartesian coordinates into range [-1,1]\n",
    "    # normalise based on max(range(x),range(y))\n",
    "    # multiply by 2 and subtract 1 to have data \n",
    "    # - centered on [0,0] \n",
    "    # - x and y each in range [-1,1]\n",
    "    range_x = x.max()-x.min()\n",
    "    range_y = y.max()-y.min()\n",
    "    range_m = max(range_x,range_y)\n",
    "    x_s = 2*((x-x.min())/range_m)-1\n",
    "    y_s = 2*((y-y.min())/range_m)-1\n",
    "    # load spline interpolant of colour scheme\n",
    "    rgb_interp = np.load('BivariateColourScheme.npy', allow_pickle=True, encoding='latin1').item()\n",
    "    # interpolate rgb values\n",
    "    rgb = np.zeros((len(x),3))\n",
    "    for i,col in enumerate(['R','G','B']):\n",
    "        rgb[:,i] = np.clip(rgb_interp[col].ev(x_s,y_s),0,1)\n",
    "    return(rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsnergb = percuniform_rgb(X[:,0],X[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "ax.scatter(X[:,0],X[:,1],5,tsnergb)\n",
    "ax.set_aspect('equal')\n",
    "ax.set_title('Color based on position')\n",
    "ax.set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now make a map of the samples, where each sample is colored based on its location in the TSNE plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.zeros_like(cl_depo)*np.nan\n",
    "# give all cells > 0 the value 1\n",
    "a[cl_depo>0] = 1\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "# modify the default figure size\n",
    "fig.set_size_inches(10,10)\n",
    "\n",
    "p = ax.imshow(a,\n",
    "              origin = 'upper',\n",
    "              cmap = 'gray',\n",
    "              vmax = 2,\n",
    "              extent = (cl_depo_meta['xllcorner'],\n",
    "                        cl_depo_meta['xllcorner']+(cl_depo_meta['ncols']*cl_depo_meta['cellsize']),\n",
    "                        cl_depo_meta['yllcorner'],\n",
    "                        cl_depo_meta['yllcorner']+(cl_depo_meta['nrows']*cl_depo_meta['cellsize'])))\n",
    "ax.set_title('Color based on TSNE projection')\n",
    "# zoom in to SA data\n",
    "ax.set_xlim(chem['Long'].min(),chem['Long'].max())\n",
    "ax.set_ylim(chem['Lat'].min(),chem['Lat'].max())\n",
    "# use scatter to plot point with color based on recharge\n",
    "s = ax.scatter(dat['Long'],dat['Lat'],2,tsnergb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
